
@article{chipilski_exact_2025,
	title = {Exact {Nonlinear} {State} {Estimation}},
	url = {https://journals.ametsoc.org/view/journals/atsc/82/4/JAS-D-24-0171.1.xml},
	doi = {10.1175/JAS-D-24-0171.1},
	abstract = {The majority of data assimilation (DA) methods in the geosciences are based on Gaussian assumptions. While such approximations facilitate efficient algorithms, they cause analysis biases and subsequent forecast degradations. Nonparametric, particle-based DA algorithms have superior accuracy, but their application to high-dimensional models still poses operational challenges. Drawing inspiration from recent advances in the fields of measure transport and generative artificial intelligence, this paper develops a new estimation-theoretic framework which can incorporate general invertible transformations in a principled way. Specifically, a conjugate transform filter (CTF) is derived and shown to extend the celebrated Kalman filter to a much broader class of non-Gaussian distributions. The new filter has several desirable properties, such as its ability to preserve statistical relationships in the prior state and converge to highly accurate observations. An ensemble approximation of the new filtering framework is also presented and validated through idealized examples. The numerical demonstrations feature bounded quantities with non-Gaussian distributions, which is a typical challenge in Earth system models. Results suggest that the greatest benefits from the new filtering framework occur when the observation errors are small relative to the forecast uncertainty and when state variables exhibit strong nonlinear dependencies. Significance Statement Data assimilation (DA) is the science of combining numerical models and observations. Common applications include estimating the state of large geophysical systems and inferring unknown model parameters. The Kalman filter and its many variants, which played a crucial role for the success of the Apollo space missions, is still the workhorse of operational DA algorithms. However, Kalman’s theory is based on highly restrictive assumptions which often compromise the DA accuracy. To address this challenge, the present article derives a new filtering theory in which the Kalman filter emerges as a special case. The flexibility of the proposed framework and its ability to integrate powerful mathematical techniques commonly used in artificial intelligence (AI) applications opens promising new avenues for improving conventional DA algorithms.},
	language = {en},
	urldate = {2025-05-23},
	author = {Chipilski, Hristo G.},
	month = apr,
	year = {2025},
	note = {Section: Journal of the Atmospheric Sciences},
	keywords = {Kalman filters, Uncertainty, Bayesian methods, Data assimilation, Ensembles, Filtering techniques},
	file = {Full Text PDF:/home/simon/Zotero/storage/FTVREMF2/Chipilski - 2025 - Exact Nonlinear State Estimation.pdf:application/pdf},
}

@misc{wagner_kalman_2022,
	title = {Kalman {Bayesian} {Neural} {Networks} for {Closed}-form {Online} {Learning}},
	url = {http://arxiv.org/abs/2110.00944},
	doi = {10.48550/arXiv.2110.00944},
	abstract = {Compared to point estimates calculated by standard neural networks, Bayesian neural networks (BNN) provide probability distributions over the output predictions and model parameters, i.e., the weights. Training the weight distribution of a BNN, however, is more involved due to the intractability of the underlying Bayesian inference problem and thus, requires efficient approximations. In this paper, we propose a novel approach for BNN learning via closed-form Bayesian inference. For this purpose, the calculation of the predictive distribution of the output and the update of the weight distribution are treated as Bayesian filtering and smoothing problems, where the weights are modeled as Gaussian random variables. This allows closed-form expressions for training the network's parameters in a sequential/online fashion without gradient descent. We demonstrate our method on several UCI datasets and compare it to the state of the art.},
	urldate = {2025-05-23},
	publisher = {arXiv},
	author = {Wagner, Philipp and Wu, Xinyang and Huber, Marco F.},
	month = nov,
	year = {2022},
	note = {arXiv:2110.00944 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 37th AAAI Conference on Artificial Intelligence (AAAI)},
	file = {Full Text PDF:/home/simon/Zotero/storage/2HUUBXXE/Wagner et al. - 2022 - Kalman Bayesian Neural Networks for Closed-form On.pdf:application/pdf;Snapshot:/home/simon/Zotero/storage/UNAGH27Y/2110.html:text/html},
}

@inproceedings{huber_bayesian_2020,
	title = {Bayesian {Perceptron}: {Towards} fully {Bayesian} {Neural} {Networks}},
	shorttitle = {Bayesian {Perceptron}},
	url = {https://ieeexplore.ieee.org/abstract/document/9303764},
	doi = {10.1109/CDC42340.2020.9303764},
	abstract = {Artificial neural networks (NNs) have become the de facto standard in machine learning. They allow learning highly nonlinear transformations in a plethora of applications. However, NNs usually only provide point estimates without systematically quantifying corresponding uncertainties. In this paper a novel approach towards fully Bayesian NNs is proposed, where training and predictions of a perceptron are performed within the Bayesian inference framework in closed-form. The weights and the predictions of the perceptron are considered Gaussian random variables. Analytical expressions for predicting the perceptron's output and for learning the weights are provided for commonly used activation functions like sigmoid or ReLU. This approach requires no computationally expensive gradient calculations and further allows sequential learning.},
	urldate = {2025-05-23},
	booktitle = {2020 59th {IEEE} {Conference} on {Decision} and {Control} ({CDC})},
	author = {Huber, Marco F.},
	month = dec,
	year = {2020},
	note = {ISSN: 2576-2370},
	keywords = {Bayes methods, Training data, Standards, Uncertainty, Training, Artificial neural networks, Probability density function},
	pages = {3179--3186},
	file = {Full Text PDF:/home/simon/Zotero/storage/TFX4HYWF/Huber - 2020 - Bayesian Perceptron Towards fully Bayesian Neural.pdf:application/pdf},
}

@inproceedings{nagel_kalman-bucy-informed_2022,
	title = {Kalman-{Bucy}-{Informed} {Neural} {Network} for {System} {Identification}},
	url = {https://ieeexplore.ieee.org/document/9993245/},
	doi = {10.1109/CDC51059.2022.9993245},
	abstract = {Identifying parameters in a system of nonlinear, ordinary differential equations is vital for designing a robust controller. However, if the system is stochastic in its nature or if only noisy measurements are available, standard optimization algorithms for system identification usually fail. We present a new approach that combines the recent advances in physics-informed neural networks and the well-known achievements of Kalman filters in order to find parameters in a continuous-time system with noisy measurements. In doing so, our approach allows estimating the parameters together with the mean value and covariance matrix of the system’s state vector. We show that the method works for complex systems by identifying the parameters of a double pendulum.},
	urldate = {2025-05-24},
	booktitle = {2022 {IEEE} 61st {Conference} on {Decision} and {Control} ({CDC})},
	author = {Nagel, Tobias and Huber, Marco F.},
	month = dec,
	year = {2022},
	note = {ISSN: 2576-2370},
	keywords = {System identification, Kalman filters, Noise measurement, Covariance matrices, Neural networks, Complex systems, Ordinary differential equations},
	pages = {1503--1508},
	annote = {EKF
},
	file = {Full Text PDF:/home/simon/Zotero/storage/ZT7DHWB8/Nagel and Huber - 2022 - Kalman-Bucy-Informed Neural Network for System Ide.pdf:application/pdf},
}

@inproceedings{deisenroth_analytic_2009,
	address = {Montreal Quebec Canada},
	title = {Analytic moment-based {Gaussian} process filtering},
	isbn = {978-1-60558-516-1},
	url = {https://dl.acm.org/doi/10.1145/1553374.1553403},
	doi = {10.1145/1553374.1553403},
	abstract = {We propose an analytic moment-based ﬁlter for nonlinear stochastic dynamic systems modeled by Gaussian processes. Exact expressions for the expected value and the covariance matrix are provided for both the prediction step and the ﬁlter step, where an additional Gaussian assumption is exploited in the latter case. Our ﬁlter does not require further approximations. In particular, it avoids ﬁnite-sample approximations. We compare the ﬁlter to a variety of Gaussian ﬁlters, that is, the EKF, the UKF, and the recent GP-UKF proposed by Ko et al. (2007).},
	language = {en},
	urldate = {2025-05-24},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Deisenroth, Marc Peter and Huber, Marco F. and Hanebeck, Uwe D.},
	month = jun,
	year = {2009},
	pages = {225--232},
	file = {Deisenroth et al. - 2009 - Analytic moment-based Gaussian process filtering.pdf:/home/simon/Zotero/storage/GEDW5T2D/Deisenroth et al. - 2009 - Analytic moment-based Gaussian process filtering.pdf:application/pdf},
}

@inproceedings{wan_unscented_2000,
	address = {Lake Louise, Alta., Canada},
	title = {The unscented {Kalman} filter for nonlinear estimation},
	isbn = {978-0-7803-5800-3},
	url = {http://ieeexplore.ieee.org/document/882463/},
	doi = {10.1109/ASSPCC.2000.882463},
	abstract = {The Extended Kalman Filter (EKF) has become a standard technique used in a number of nonlinear estimation and machine learning applications. These include estimating the state of a nonlinear dynamic system, estimating parameters for nonlinear system identiﬁcation (e.g., learning the weights of a neural network), and dual estimation (e.g., the Expectation Maximization (EM) algorithm) where both states and parameters are estimated simultaneously. This paper points out the ﬂaws in using the EKF, and introduces an improvement, the Unscented Kalman Filter (UKF), proposed by Julier and Uhlman [5]. A central and vital operation performed in the Kalman Filter is the propagation of a Gaussian random variable (GRV) through the system dynamics. In the EKF, the state distribution is approximated by a GRV, which is then propagated analytically through the ﬁrst-order linearization of the nonlinear system. This can introduce large errors in the true posterior mean and covariance of the transformed GRV, which may lead to sub-optimal performance and sometimes divergence of the ﬁlter. The UKF addresses this problem by using a deterministic sampling approach. The state distribution is again approximated by a GRV, but is now represented using a minimal set of carefully chosen sample points. These sample points completely capture the true mean and covariance of the GRV, and when propagated through the true nonlinear system, captures the posterior mean and covariance accurately to the 3rd order (Taylor series expansion) for any nonlinearity. The EKF, in contrast, only achieves ﬁrst-order accuracy. Remarkably, the computational complexity of the UKF is the same order as that of the EKF.},
	language = {en},
	urldate = {2025-05-24},
	booktitle = {Proceedings of the {IEEE} 2000 {Adaptive} {Systems} for {Signal} {Processing}, {Communications}, and {Control} {Symposium} ({Cat}. {No}.{00EX373})},
	publisher = {IEEE},
	author = {Wan, E.A. and Van Der Merwe, R.},
	year = {2000},
	pages = {153--158},
	file = {Wan and Van Der Merwe - 2000 - The unscented Kalman filter for nonlinear estimati.pdf:/home/simon/Zotero/storage/PAUPRE4J/Wan and Van Der Merwe - 2000 - The unscented Kalman filter for nonlinear estimati.pdf:application/pdf},
}

@article{julier_unscented_2004,
	title = {Unscented {Filtering} and {Nonlinear} {Estimation}},
	volume = {92},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9219},
	url = {http://ieeexplore.ieee.org/document/1271397/},
	doi = {10.1109/JPROC.2003.823141},
	language = {en},
	number = {3},
	urldate = {2025-05-24},
	journal = {Proceedings of the IEEE},
	author = {Julier, S.J. and Uhlmann, J.K.},
	month = mar,
	year = {2004},
	pages = {401--422},
	file = {Julier and Uhlmann - 2004 - Unscented Filtering and Nonlinear Estimation.pdf:/home/simon/Zotero/storage/RE87AX3X/Julier and Uhlmann - 2004 - Unscented Filtering and Nonlinear Estimation.pdf:application/pdf},
}

@article{chipilski_exact_2025-1,
	title = {Exact {Nonlinear} {State} {Estimation}},
	url = {https://journals.ametsoc.org/view/journals/atsc/82/4/JAS-D-24-0171.1.xml},
	doi = {10.1175/JAS-D-24-0171.1},
	abstract = {The majority of data assimilation (DA) methods in the geosciences are based on Gaussian assumptions. While such approximations facilitate efficient algorithms, they cause analysis biases and subsequent forecast degradations. Nonparametric, particle-based DA algorithms have superior accuracy, but their application to high-dimensional models still poses operational challenges. Drawing inspiration from recent advances in the fields of measure transport and generative artificial intelligence, this paper develops a new estimation-theoretic framework which can incorporate general invertible transformations in a principled way. Specifically, a conjugate transform filter (CTF) is derived and shown to extend the celebrated Kalman filter to a much broader class of non-Gaussian distributions. The new filter has several desirable properties, such as its ability to preserve statistical relationships in the prior state and converge to highly accurate observations. An ensemble approximation of the new filtering framework is also presented and validated through idealized examples. The numerical demonstrations feature bounded quantities with non-Gaussian distributions, which is a typical challenge in Earth system models. Results suggest that the greatest benefits from the new filtering framework occur when the observation errors are small relative to the forecast uncertainty and when state variables exhibit strong nonlinear dependencies. Significance Statement Data assimilation (DA) is the science of combining numerical models and observations. Common applications include estimating the state of large geophysical systems and inferring unknown model parameters. The Kalman filter and its many variants, which played a crucial role for the success of the Apollo space missions, is still the workhorse of operational DA algorithms. However, Kalman’s theory is based on highly restrictive assumptions which often compromise the DA accuracy. To address this challenge, the present article derives a new filtering theory in which the Kalman filter emerges as a special case. The flexibility of the proposed framework and its ability to integrate powerful mathematical techniques commonly used in artificial intelligence (AI) applications opens promising new avenues for improving conventional DA algorithms.},
	language = {en},
	urldate = {2025-05-24},
	author = {Chipilski, Hristo G.},
	month = apr,
	year = {2025},
	note = {Section: Journal of the Atmospheric Sciences},
	keywords = {Kalman filters, Uncertainty, Bayesian methods, Data assimilation, Ensembles, Filtering techniques},
	file = {Full Text PDF:/home/simon/Zotero/storage/CTP8YQCB/Chipilski - 2025 - Exact Nonlinear State Estimation.pdf:application/pdf},
}
